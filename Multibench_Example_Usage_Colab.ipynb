{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multibench Example Usage Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome!\n",
        "\n",
        "This example shows a very basic usage case of MultiBench. In particular, it demonstrates how to use MultiBench with the affective computing dataset MOSI, and how to use it with a very simple fusion model.\n",
        "\n",
        "While this will be simple, it will show off most of the capabilities of MultiBench, and most of the conventions at the heart of the system.\n",
        "\n",
        "To begin, let's clone the repo and setup our interpreter to run commands inside the folder."
      ],
      "metadata": {
        "id": "JCnG1gTFJQ-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHmaOz8aEZx6",
        "outputId": "7a0e2552-248c-4a86-af7d-24c3639efd2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MultiBench'...\n",
            "remote: Enumerating objects: 6943, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 6943 (delta 72), reused 121 (delta 60), pack-reused 6789\u001b[K\n",
            "Receiving objects: 100% (6943/6943), 51.07 MiB | 20.67 MiB/s, done.\n",
            "Resolving deltas: 100% (4258/4258), done.\n",
            "/content/MultiBench\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git\n",
        "%cd MultiBench"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U memory_profiler"
      ],
      "metadata": {
        "id": "V_yVJqR0iicJ",
        "outputId": "6fcb78da-c64e-4778-d8e5-22112a9f6739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to download the data folder with MOSI, MOSEI, SARCASM and MUSTARD files using the below command. If this does not work for you, please download the data file locally, and upload it to the folder \"/content/MultiBench/data/\""
      ],
      "metadata": {
        "id": "tUqFe87DIYu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown && gdown https://drive.google.com/drive/folders/1drao0aXgS1tPCr55riqMLfo0pMPzDAR-?usp=sharing -O /content/MultiBench/ --folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwZS6dfGElh8",
        "outputId": "18ee22f6-d7dc-4987-f4fa-f7dfe846a251"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Retrieving folder contents\n",
            "Processing file 1i8ePqY6HQ3m4joa5bjNRj5q98F9Bo4lF humor.pkl\n",
            "Processing file 1uhUloaigNUMYU7Wq_EZj58pCGIoto34T mosei_raw.pkl\n",
            "Processing file 13McsNwX1_kTnA3i2KyDWlLWnh52Kvz4V mosi_raw.pkl\n",
            "Processing file 1dN7AT3ytEnCgL18FnKN-jXN4GkEQFKZS sarcasm.pkl\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1i8ePqY6HQ3m4joa5bjNRj5q98F9Bo4lF\n",
            "From (redirected): https://drive.google.com/uc?id=1i8ePqY6HQ3m4joa5bjNRj5q98F9Bo4lF&confirm=t&uuid=0bb7924c-18f5-476d-b9ed-f5f24c37b506\n",
            "To: /content/MultiBench/data/humor.pkl\n",
            "100% 1.22G/1.22G [00:13<00:00, 89.2MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1uhUloaigNUMYU7Wq_EZj58pCGIoto34T\n",
            "From (redirected): https://drive.google.com/uc?id=1uhUloaigNUMYU7Wq_EZj58pCGIoto34T&confirm=t&uuid=2dd28ee5-af8a-492a-91bf-f05f37d14d59\n",
            "To: /content/MultiBench/data/mosei_raw.pkl\n",
            "100% 9.94G/9.94G [01:48<00:00, 91.5MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13McsNwX1_kTnA3i2KyDWlLWnh52Kvz4V\n",
            "From (redirected): https://drive.google.com/uc?id=13McsNwX1_kTnA3i2KyDWlLWnh52Kvz4V&confirm=t&uuid=70192600-4303-4a0d-84cd-349b5aa94a4b\n",
            "To: /content/MultiBench/data/mosi_raw.pkl\n",
            "100% 357M/357M [00:02<00:00, 155MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1dN7AT3ytEnCgL18FnKN-jXN4GkEQFKZS\n",
            "From (redirected): https://drive.google.com/uc?id=1dN7AT3ytEnCgL18FnKN-jXN4GkEQFKZS&confirm=t&uuid=178207a2-50ac-4c30-97b4-412248b937b5\n",
            "To: /content/MultiBench/data/sarcasm.pkl\n",
            "100% 208M/208M [00:01<00:00, 113MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Colab famously has bad handling of Conda env files, we'll install the dependencies manually so that it works. Please note that other systems might require installation of a long list of other dependencies."
      ],
      "metadata": {
        "id": "nd1ZaCe6JOoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, let's import some of MultiBench and get working:"
      ],
      "metadata": {
        "id": "n5S9YcS9J6yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "mk9zuDMrKMAP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll import and create the dataloader for the MOSI dataset, which we're working with:"
      ],
      "metadata": {
        "id": "U0DyV1CVKpyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the associated dataloader for affect datasets, which MOSI is a part of.\n",
        "from datasets.affect.get_data import get_dataloader\n",
        "\n",
        "# Create the training, validation, and test-set dataloaders.\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/data/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)"
      ],
      "metadata": {
        "id": "l5enTYMkKtci"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's define our MultiModal model to test. MultiBench divides models into three separate portions.\n",
        "\n",
        "Firstly, let's define the encoders of the raw modality information, which come from the \"unimodals\" section of MultiBench:"
      ],
      "metadata": {
        "id": "riE35efnK5Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we'll import several common modules should you want to mess with this more.\n",
        "from unimodals.common_models import GRU, MLP, Sequential, Identity\n",
        "\n",
        "# As this example is meant to be simple and easy to train, we'll pass in identity\n",
        "# functions for each of the modalities in MOSI:\n",
        "encoders = [Identity().cuda(), Identity().cuda(), Identity().cuda()]"
      ],
      "metadata": {
        "id": "n8ZBils-LGgW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's define the fusion paradigm, which will govern how we take the current modalities, and combine them.\n",
        "\n",
        "For this example, we'll use the ConcatEarly fusion, which just concatenates the inputs along the second dimension."
      ],
      "metadata": {
        "id": "XBnSFG3TLZFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a fusion paradigm, in this case early concatenation.\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "# Initialize the fusion module\n",
        "fusion = ConcatEarly().cuda()"
      ],
      "metadata": {
        "id": "ifsONTlIMVyb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we'll define a 'head' module, which takes the output of the fusion module, and applies transformations to get an output that correponds to our problem - sarcasm detection."
      ],
      "metadata": {
        "id": "-mS5anKyMWPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head = Sequential(GRU(409, 512, dropout=True, has_padding=False,\n",
        "                  batch_first=True, last_only=True), MLP(512, 512, 1)).cuda()"
      ],
      "metadata": {
        "id": "6IMQNFDXFJNs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And with that, we're almost done! Now we just need to put them into one of MultiBench's training loops, and set it running:"
      ],
      "metadata": {
        "id": "2nUXcxm2MndX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard supervised learning training loop\n",
        "from training_structures.Supervised_Learning import train, test\n",
        "\n",
        "# For more information regarding parameters for any system, feel free to check out the documentation\n",
        "# at multibench.readthedocs.io!\n",
        "train(encoders, fusion, head, traindata, validdata, 100, task=\"regression\", optimtype=torch.optim.AdamW,\n",
        "      is_packed=False, lr=1e-3, save='mosi_ef_r0.pt', weight_decay=0.01, objective=torch.nn.L1Loss())\n",
        "\n",
        "print(\"Testing:\")\n",
        "model = torch.load('mosi_ef_r0.pt').cuda()\n",
        "test(model, testdata, 'affect', is_packed=False,\n",
        "     criterion=torch.nn.L1Loss(), task=\"posneg-classification\", no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG3OYAByJ-sX",
        "outputId": "e828da50-f357-42d4-c140-ce4713e3fb51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: 1.3936829566955566\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: 1.3801870346069336\n",
            "Saving Best\n",
            "Epoch 2 train loss: tensor(1.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: 1.3857842683792114\n",
            "Epoch 3 train loss: tensor(1.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: 1.3853166103363037\n",
            "Epoch 4 train loss: tensor(1.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: 1.3821818828582764\n",
            "Epoch 5 train loss: tensor(1.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: 1.3856353759765625\n",
            "Epoch 6 train loss: tensor(1.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: 1.3768967390060425\n",
            "Saving Best\n",
            "Epoch 7 train loss: tensor(1.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: 1.3840895891189575\n",
            "Epoch 8 train loss: tensor(1.3198, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: 1.3883512020111084\n",
            "Epoch 9 train loss: tensor(1.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: 1.3760700225830078\n",
            "Saving Best\n",
            "Epoch 10 train loss: tensor(1.3178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: 1.3788858652114868\n",
            "Epoch 11 train loss: tensor(1.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: 1.383111596107483\n",
            "Epoch 12 train loss: tensor(1.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: 1.5719040632247925\n",
            "Epoch 13 train loss: tensor(1.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: 1.3855825662612915\n",
            "Epoch 14 train loss: tensor(1.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: 1.3860911130905151\n",
            "Epoch 15 train loss: tensor(1.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: 1.3918334245681763\n",
            "Epoch 16 train loss: tensor(1.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: 1.3903008699417114\n",
            "Epoch 17 train loss: tensor(1.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: 1.3649308681488037\n",
            "Saving Best\n",
            "Epoch 18 train loss: tensor(1.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: 1.472808837890625\n",
            "Epoch 19 train loss: tensor(1.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: 1.5477863550186157\n",
            "Epoch 20 train loss: tensor(1.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: 1.3433568477630615\n",
            "Saving Best\n",
            "Epoch 21 train loss: tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: 1.395989179611206\n",
            "Epoch 22 train loss: tensor(1.0842, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: 1.3656624555587769\n",
            "Epoch 23 train loss: tensor(1.0366, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: 1.288399577140808\n",
            "Saving Best\n",
            "Epoch 24 train loss: tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: 1.370102882385254\n",
            "Epoch 25 train loss: tensor(0.9744, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: 1.398789405822754\n",
            "Epoch 26 train loss: tensor(0.9553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: 1.289952039718628\n",
            "Epoch 27 train loss: tensor(0.8948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: 1.3521180152893066\n",
            "Epoch 28 train loss: tensor(0.9124, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: 1.2352144718170166\n",
            "Saving Best\n",
            "Epoch 29 train loss: tensor(0.9098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: 1.2410415410995483\n",
            "Epoch 30 train loss: tensor(0.8833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: 1.2783286571502686\n",
            "Epoch 31 train loss: tensor(0.8174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: 1.3438321352005005\n",
            "Epoch 32 train loss: tensor(0.7766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: 1.2123867273330688\n",
            "Saving Best\n",
            "Epoch 33 train loss: tensor(0.7545, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: 1.2975728511810303\n",
            "Epoch 34 train loss: tensor(0.7443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: 1.2292742729187012\n",
            "Epoch 35 train loss: tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: 1.2660733461380005\n",
            "Epoch 36 train loss: tensor(0.6878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: 1.177274227142334\n",
            "Saving Best\n",
            "Epoch 37 train loss: tensor(0.6843, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: 1.272188425064087\n",
            "Epoch 38 train loss: tensor(0.6636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: 1.3338327407836914\n",
            "Epoch 39 train loss: tensor(0.6641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: 1.2234249114990234\n",
            "Epoch 40 train loss: tensor(0.6452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: 1.3022600412368774\n",
            "Epoch 41 train loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: 1.2083232402801514\n",
            "Epoch 42 train loss: tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: 1.1929186582565308\n",
            "Epoch 43 train loss: tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: 1.2015093564987183\n",
            "Epoch 44 train loss: tensor(0.5921, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: 1.203865647315979\n",
            "Epoch 45 train loss: tensor(0.5913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: 1.2162333726882935\n",
            "Epoch 46 train loss: tensor(0.5396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: 1.202097773551941\n",
            "Epoch 47 train loss: tensor(0.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: 1.2813307046890259\n",
            "Epoch 48 train loss: tensor(0.5093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: 1.209816575050354\n",
            "Epoch 49 train loss: tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: 1.2626466751098633\n",
            "Epoch 50 train loss: tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: 1.2392210960388184\n",
            "Epoch 51 train loss: tensor(0.4773, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: 1.2262420654296875\n",
            "Epoch 52 train loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: 1.2071775197982788\n",
            "Epoch 53 train loss: tensor(0.4613, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: 1.2492613792419434\n",
            "Epoch 54 train loss: tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: 1.2790812253952026\n",
            "Epoch 55 train loss: tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: 1.2604217529296875\n",
            "Epoch 56 train loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: 1.2516337633132935\n",
            "Epoch 57 train loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: 1.244995355606079\n",
            "Epoch 58 train loss: tensor(0.4349, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: 1.2476060390472412\n",
            "Epoch 59 train loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: 1.2464208602905273\n",
            "Epoch 60 train loss: tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: 1.2459726333618164\n",
            "Epoch 61 train loss: tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: 1.2114468812942505\n",
            "Epoch 62 train loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: 1.2711533308029175\n",
            "Epoch 63 train loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: 1.2278904914855957\n",
            "Epoch 64 train loss: tensor(0.3744, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: 1.2715615034103394\n",
            "Epoch 65 train loss: tensor(0.3662, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: 1.2610795497894287\n",
            "Epoch 66 train loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: 1.266817569732666\n",
            "Epoch 67 train loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: 1.2557779550552368\n",
            "Epoch 68 train loss: tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: 1.2205944061279297\n",
            "Epoch 69 train loss: tensor(0.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: 1.2442547082901\n",
            "Epoch 70 train loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: 1.2706751823425293\n",
            "Epoch 71 train loss: tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: 1.2495850324630737\n",
            "Epoch 72 train loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: 1.2133972644805908\n",
            "Epoch 73 train loss: tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: 1.2302143573760986\n",
            "Epoch 74 train loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: 1.236228346824646\n",
            "Epoch 75 train loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: 1.2708337306976318\n",
            "Epoch 76 train loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: 1.3005887269973755\n",
            "Epoch 77 train loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: 1.2473289966583252\n",
            "Epoch 78 train loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: 1.2187422513961792\n",
            "Epoch 79 train loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: 1.252183198928833\n",
            "Epoch 80 train loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: 1.3081938028335571\n",
            "Epoch 81 train loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: 1.257398009300232\n",
            "Epoch 82 train loss: tensor(0.2879, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 82 valid loss: 1.2398900985717773\n",
            "Epoch 83 train loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 83 valid loss: 1.2643622159957886\n",
            "Epoch 84 train loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 84 valid loss: 1.2891613245010376\n",
            "Epoch 85 train loss: tensor(0.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 85 valid loss: 1.2484915256500244\n",
            "Epoch 86 train loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 86 valid loss: 1.2690154314041138\n",
            "Epoch 87 train loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 87 valid loss: 1.2519636154174805\n",
            "Epoch 88 train loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 88 valid loss: 1.2705734968185425\n",
            "Epoch 89 train loss: tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 89 valid loss: 1.2411856651306152\n",
            "Epoch 90 train loss: tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 90 valid loss: 1.224269986152649\n",
            "Epoch 91 train loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 91 valid loss: 1.2920409440994263\n",
            "Epoch 92 train loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 92 valid loss: 1.2716690301895142\n",
            "Epoch 93 train loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 93 valid loss: 1.229532241821289\n",
            "Epoch 94 train loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 94 valid loss: 1.2345921993255615\n",
            "Epoch 95 train loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 95 valid loss: 1.254152536392212\n",
            "Epoch 96 train loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 96 valid loss: 1.2380635738372803\n",
            "Epoch 97 train loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 97 valid loss: 1.3016786575317383\n",
            "Epoch 98 train loss: tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 98 valid loss: 1.207167387008667\n",
            "Epoch 99 train loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 99 valid loss: 1.2544769048690796\n",
            "Training Time: 110.45130372047424\n",
            "Training Peak Mem: 1393.60546875\n",
            "Training Params: 1680897\n",
            "Testing:\n",
            "acc: 0.6341463414634146, 0.6268221574344023\n",
            "Inference Time: 0.3848698139190674\n",
            "Inference Params: 1680897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And with that, you've taken your first step into using MultiBench! We hope you find the library useful, and feel free to make an issue on GitHub should there be any confusions regarding how to use an aspect of the package."
      ],
      "metadata": {
        "id": "wPVLMGGtM99W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgx9AHpZNP_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}